{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import json\n",
    "from utils import *\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token= os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=token, base_url=\"https://chat.int.bayer.com/api/v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Total number of available models: 53'\n"
     ]
    }
   ],
   "source": [
    "all_models = client.models.list()\n",
    "\n",
    "pprint(f\"{(all_models.data)}\")\n",
    "pprint(f\"Total number of available models: {len(all_models.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_database(db_path):\n",
    "    \"\"\"Explore database schema\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Get all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    print(f\"📊 Database: {db_path}\")\n",
    "    print(f\"📋 Tables found: {len(tables)}\\n\")\n",
    "    \n",
    "    schema = {}\n",
    "    for table in tables:\n",
    "        cursor.execute(f\"PRAGMA table_info({table})\")\n",
    "        columns = cursor.fetchall()\n",
    "        schema[table] = [col[1] for col in columns]\n",
    "        print(f\"  • {table}: {', '.join(schema[table][:5])}{'...' if len(schema[table]) > 5 else ''}\")\n",
    "    \n",
    "    conn.close()\n",
    "    return schema\n",
    "\n",
    "# Explore chinook database\n",
    "schema = explore_database(\"../data/chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_str = str(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(schema_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_usage=calculate_context_percentage(schema_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv(\"OPEENAI_API_KEY\")\n",
    "model = 'o4-mini'\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://chat.int.bayer.com/api/v2\",\n",
    "    openai_api_key=token,\n",
    "    model=model,\n",
    "    temperature=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataAnalysisAgent:\n",
    "    \"\"\"Analyzes data using LLM-generated SQL\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path, llm, schema):\n",
    "        self.db_path = db_path\n",
    "        self.llm = llm\n",
    "        self.schema = schema\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        \n",
    "    def analyze(self, user_query: str, allowed_tables: list = None) -> dict:\n",
    "        \"\"\"Main analysis method\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"🔍 Query: {user_query}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        sql_query = self._generate_sql(user_query, allowed_tables)\n",
    "        print(f\"\\n Generated SQL:\\n{sql_query}\\n\")\n",
    "        \n",
    "        if self._is_safe_query(sql_query):\n",
    "            try:\n",
    "                df = pd.read_sql_query(sql_query, self.conn)\n",
    "                print(f\" Query executed: {len(df)} rows returned\\n\")\n",
    "                \n",
    "                insights = self._generate_insights(user_query, df)\n",
    "                \n",
    "                return {\n",
    "                    \"status\": \"success\",\n",
    "                    \"query\": user_query,\n",
    "                    \"sql\": sql_query,\n",
    "                    \"data\": df,\n",
    "                    \"insights\": insights,\n",
    "                    \"rows\": len(df)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"status\": \"error\",\n",
    "                    \"error\": str(e),\n",
    "                    \"query\": user_query\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"Unsafe query detected\",\n",
    "                \"query\": user_query\n",
    "            }\n",
    "    \n",
    "    def _generate_sql(self, user_query: str, allowed_tables: list = None) -> str:\n",
    "        \"\"\"Generate SQL from natural language\"\"\"\n",
    "        tables_info = \"\\n\".join([\n",
    "            f\"- {table}: {', '.join(cols)}\"\n",
    "            for table, cols in self.schema.items()\n",
    "            if allowed_tables is None or table in allowed_tables\n",
    "        ])\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"You are an expert SQL generator for SQLite databases.           \n",
    "                DATABASE SCHEMA:\n",
    "                {schema}\n",
    "                USER QUERY: {query}\n",
    "                Generate a safe, efficient SELECT query. Rules:\n",
    "                1. ONLY use SELECT statements (no INSERT, UPDATE, DELETE, DROP)\n",
    "                2. Include LIMIT clause if not specified (default LIMIT 100)\n",
    "                3. Use proper JOINs when needed\n",
    "                4. Return ONLY the SQL query, no explanations\n",
    "                SQL Query:\"\"\")\n",
    "        \n",
    "        response = self.llm.invoke(prompt.format(schema=tables_info, query=user_query))\n",
    "        \n",
    "        # Clean the response\n",
    "        sql = response.content.strip()\n",
    "        # Remove markdown code blocks if present\n",
    "        sql = sql.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        return sql\n",
    "    \n",
    "    def _is_safe_query(self, sql: str) -> bool:\n",
    "        \"\"\"Check if SQL query is safe\"\"\"\n",
    "        sql_upper = sql.upper()\n",
    "        dangerous_keywords = ['DROP', 'DELETE', 'UPDATE', 'INSERT', 'ALTER', 'CREATE', 'TRUNCATE']\n",
    "        \n",
    "        for keyword in dangerous_keywords:\n",
    "            if keyword in sql_upper:\n",
    "                print(f\"⚠️  Dangerous keyword detected: {keyword}\")\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _generate_insights(self, query: str, df: pd.DataFrame) -> str:\n",
    "        \"\"\"Generate natural language insights\"\"\"\n",
    "        data_summary = df.head(10).to_string()\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Based on this query and results, provide 2-3 key insights in bullet points.\n",
    "                QUERY: {query}\n",
    "                RESULTS (first 10 rows):\n",
    "                {data}\n",
    "                Key Insights (2-3 bullets):\"\"\")\n",
    "        \n",
    "        response = self.llm.invoke(prompt.format(query=query, data=data_summary))\n",
    "        \n",
    "        return response.content.strip()\n",
    "    \n",
    "    def close(self):\n",
    "        self.conn.close()\n",
    "\n",
    "analysis_agent = DataAnalysisAgent(\"../data/chinook.db\", llm, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_agent.analyze(\"Give me top 10 artist with most albulmns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company Style Configuration for plottinng and visualziations\n",
    "COMPANY_STYLE = {\n",
    "    \"colors\": [\"#2E86AB\", \"#A23B72\", \"#F18F01\", \"#C73E1D\", \"#6A994E\"],\n",
    "    \"font_size\": 12,\n",
    "    \"figure_size\": (10, 6),\n",
    "    \"dpi\": 100\n",
    "}\n",
    "\n",
    "sns.set_palette(COMPANY_STYLE[\"colors\"])\n",
    "plt.rcParams['figure.figsize'] = COMPANY_STYLE[\"figure_size\"]\n",
    "plt.rcParams['figure.dpi'] = COMPANY_STYLE[\"dpi\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationAgent:\n",
    "    \"\"\"Creates visualizations with company branding\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, style_config=COMPANY_STYLE):\n",
    "        self.llm = llm\n",
    "        self.style = style_config\n",
    "        \n",
    "    def visualize(self, data: pd.DataFrame, query: str, output_dir=\"../outputs\") -> dict:\n",
    "        \"\"\"Create appropriate visualization\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Creating Visualization\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        chart_type = self._determine_chart_type(data, query)\n",
    "        print(f\" Chart type: {chart_type}\\n\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=self.style['figure_size'])\n",
    "        \n",
    "        if chart_type == 'bar':\n",
    "            self._create_bar_chart(data, ax)\n",
    "        elif chart_type == 'line':\n",
    "            self._create_line_chart(data, ax)\n",
    "        elif chart_type == 'pie':\n",
    "            self._create_pie_chart(data, ax)\n",
    "        elif chart_type == 'scatter':\n",
    "            self._create_scatter_plot(data, ax)\n",
    "        else:\n",
    "            self._create_bar_chart(data, ax)  # default\n",
    "        \n",
    "        # Apply company branding\n",
    "        self._apply_branding(ax, query)\n",
    "        \n",
    "        # Save\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"viz_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filepath, dpi=self.style['dpi'], bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Saved: {filepath}\\n\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"chart_type\": chart_type,\n",
    "            \"filepath\": filepath\n",
    "        }\n",
    "    \n",
    "    def _determine_chart_type(self, df: pd.DataFrame, query: str) -> str:\n",
    "        \"\"\"Use LLM to determine best chart type\"\"\"\n",
    "        data_info = f\"Columns: {list(df.columns)}, Rows: {len(df)}, Types: {df.dtypes.to_dict()}\"\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Given this data and query, suggest ONE chart type.\n",
    "                DATA INFO: {data_info}\n",
    "                QUERY: {query}\n",
    "                Choose from: bar, line, pie, scatter\n",
    "                Return ONLY the chart type, nothing else:\"\"\")\n",
    "        \n",
    "        response = self.llm.invoke(prompt.format(data_info=data_info, query=query))\n",
    "        \n",
    "        chart_type = response.content.strip().lower()\n",
    "        return chart_type if chart_type in ['bar', 'line', 'pie', 'scatter'] else 'bar'\n",
    "    \n",
    "    def _create_bar_chart(self, df, ax):\n",
    "        \"\"\"Create bar chart\"\"\"\n",
    "        # Use first column as x, second as y\n",
    "        if len(df.columns) >= 2:\n",
    "            x_col, y_col = df.columns[0], df.columns[1]\n",
    "            df_plot = df.head(10)  # Limit to top 10\n",
    "            ax.bar(range(len(df_plot)), df_plot[y_col], color=self.style['colors'][0])\n",
    "            ax.set_xticks(range(len(df_plot)))\n",
    "            ax.set_xticklabels(df_plot[x_col], rotation=45, ha='right')\n",
    "            ax.set_xlabel(x_col)\n",
    "            ax.set_ylabel(y_col)\n",
    "    \n",
    "    def _create_line_chart(self, df, ax):\n",
    "        \"\"\"Create line chart\"\"\"\n",
    "        if len(df.columns) >= 2:\n",
    "            x_col, y_col = df.columns[0], df.columns[1]\n",
    "            ax.plot(df[x_col], df[y_col], marker='o', color=self.style['colors'][0], linewidth=2)\n",
    "            ax.set_xlabel(x_col)\n",
    "            ax.set_ylabel(y_col)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _create_pie_chart(self, df, ax):\n",
    "        \"\"\"Create pie chart\"\"\"\n",
    "        if len(df.columns) >= 2:\n",
    "            labels_col, values_col = df.columns[0], df.columns[1]\n",
    "            df_plot = df.head(10)\n",
    "            ax.pie(df_plot[values_col], labels=df_plot[labels_col], autopct='%1.1f%%',\n",
    "                   colors=self.style['colors'])\n",
    "    \n",
    "    def _create_scatter_plot(self, df, ax):\n",
    "        \"\"\"Create scatter plot\"\"\"\n",
    "        if len(df.columns) >= 2:\n",
    "            x_col, y_col = df.columns[0], df.columns[1]\n",
    "            ax.scatter(df[x_col], df[y_col], alpha=0.6, color=self.style['colors'][0])\n",
    "            ax.set_xlabel(x_col)\n",
    "            ax.set_ylabel(y_col)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _apply_branding(self, ax, query):\n",
    "        \"\"\"Apply company branding\"\"\"\n",
    "        # Title based on query (simplified)\n",
    "        title = query[:50] + \"...\" if len(query) > 50 else query\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Company watermark\n",
    "        ax.text(0.99, 0.01, 'Company Analytics ©', \n",
    "                transform=ax.transAxes,\n",
    "                fontsize=8, alpha=0.5,\n",
    "                ha='right', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_agent = VisualizationAgent(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_workflow(query, user_role=\"analyst\"):\n",
    "    \"\"\"Run complete analysis + visualization workflow\"\"\"\n",
    "    \n",
    "    # Define permissions (simulated)\n",
    "    permissions = {\n",
    "        \"analyst\": [\"artists\", \"albums\", \"tracks\", \"invoices\", \"customers\"],\n",
    "        \"viewer\": [\"artists\", \"albums\", \"tracks\"],\n",
    "        \"admin\": None  # all tables\n",
    "    }\n",
    "    \n",
    "    allowed_tables = permissions.get(user_role)\n",
    "    \n",
    "    analysis_result = analysis_agent.analyze(query, allowed_tables)\n",
    "    \n",
    "    if analysis_result[\"status\"] == \"success\":\n",
    "        print(analysis_result[\"insights\"])\n",
    "        print(f\"\\nData shape: {analysis_result['data'].shape}\")\n",
    "        display(analysis_result[\"data\"].head())\n",
    "        \n",
    "        viz_result = viz_agent.visualize(analysis_result[\"data\"], query)\n",
    "        \n",
    "        return {\n",
    "            \"analysis\": analysis_result,\n",
    "            \"visualization\": viz_result\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Error: {analysis_result.get('error')}\")\n",
    "        return analysis_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TEST 1: Top 10 Selling Artists\")\n",
    "result1 = run_complete_workflow(\n",
    "    \"Show me the top 10 artists by total sales amount\",\n",
    "    user_role=\"analyst\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
